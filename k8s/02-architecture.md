# 第二层：核心架构 (What) - 深度展开

## 1. 架构设计的第一性原理

### 1.1 K8s 需要解决什么问题？

```
问题拆解：

1. 状态存储    → 期望状态存在哪里？谁是"真相来源"？
2. 统一入口    → 用户/程序如何与集群交互？
3. 调度决策    → Pod 应该跑在哪个 Node？
4. 状态调和    → 谁来驱动"期望→现实"的转换？
5. 本地执行    → 谁在 Node 上真正启动容器？
6. 网络通信    → Pod 之间、Service 之间如何通信？
```

### 1.2 架构总览

```
┌─────────────────────────────────────────────────────────────────┐
│                     Control Plane (Master)                      │
│                                                                 │
│  ┌─────────────┐  ┌─────────────┐  ┌──────────────────────────┐│
│  │ API Server  │  │  Scheduler  │  │   Controller Manager     ││
│  │  (门面)     │  │  (调度器)    │  │   (控制器集合)           ││
│  └──────┬──────┘  └─────────────┘  └──────────────────────────┘│
│         │                                                       │
│  ┌──────▼──────┐                                                │
│  │    etcd     │  ← 分布式 KV 存储，唯一真相来源                 │
│  └─────────────┘                                                │
└─────────────────────────────────────────────────────────────────┘
          │
          │ Watch/Update
          ▼
┌─────────────────────────────────────────────────────────────────┐
│                      Worker Node                                │
│                                                                 │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────┐ │
│  │   Kubelet   │  │ Kube-proxy  │  │   Container Runtime     │ │
│  │  (节点代理)  │  │  (网络代理)  │  │   (containerd/CRI-O)   │ │
│  └─────────────┘  └─────────────┘  └─────────────────────────┘ │
│                                                                 │
│  ┌─────────────────────────────────────────────────────────┐   │
│  │  Pod        Pod        Pod        Pod                   │   │
│  └─────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────┘
```

---

## 2. Control Plane 组件详解

### 2.1 etcd - 集群的"大脑记忆"

```
本质：分布式强一致性 KV 存储

┌────────────────────────────────────────────────────────┐
│                        etcd                            │
│                                                        │
│   Key                          Value                   │
│   ─────────────────────────────────────────────────    │
│   /registry/pods/default/nginx-xxx    { pod spec... } │
│   /registry/deployments/default/web   { deploy... }   │
│   /registry/services/default/api      { service... }  │
│   ...                                                  │
└────────────────────────────────────────────────────────┘

关键特性：
  - Raft 共识算法 → 强一致性
  - Watch 机制    → 变更通知
  - 唯一写入者    → 只有 API Server 能写

为什么选择 etcd？
  - 高可用（3/5/7 节点集群）
  - 强一致性（不会读到过期数据）
  - Watch 支持（事件驱动架构的基础）
```

### 2.2 API Server - 集群的"前门"

```
本质：RESTful API 网关 + 认证授权 + 准入控制

所有请求必经之路：

  kubectl ─────┐
  Dashboard ───┼───▶ API Server ───▶ etcd
  Controller ──┤         │
  Kubelet ─────┘         ▼
                    认证 → 授权 → 准入控制
```

**核心职责：**

```
1. 认证 (Authentication)
   ─────────────────────────
   你是谁？
   - 证书、Token、OIDC...

2. 授权 (Authorization)
   ─────────────────────────
   你能做什么？
   - RBAC：Role-Based Access Control

3. 准入控制 (Admission Control)
   ─────────────────────────
   请求是否合规？
   - 资源配额检查
   - Pod 安全策略
   - 自动注入 Sidecar（如 Istio）

4. 验证与持久化
   ─────────────────────────
   - Schema 验证
   - 写入 etcd
```

**API 设计哲学：**

```
RESTful + 资源导向

GET    /api/v1/namespaces/default/pods          # 列出 pods
POST   /api/v1/namespaces/default/pods          # 创建 pod
GET    /api/v1/namespaces/default/pods/nginx    # 获取特定 pod
PUT    /api/v1/namespaces/default/pods/nginx    # 更新 pod
DELETE /api/v1/namespaces/default/pods/nginx    # 删除 pod
WATCH  /api/v1/namespaces/default/pods?watch=true  # 监听变化
```

### 2.3 Scheduler - 集群的"调度员"

```
本质：为未调度的 Pod 选择最佳 Node

输入：待调度的 Pod
输出：Pod 应该运行在哪个 Node

┌─────────────────────────────────────────────────────────┐
│                    Scheduling 流程                       │
│                                                         │
│   新 Pod ──▶ 过滤 (Filtering) ──▶ 打分 (Scoring) ──▶ 绑定 │
│              │                    │                     │
│              ▼                    ▼                     │
│         排除不满足条件的        给剩余 Node 打分         │
│         Node                   选最高分                 │
└─────────────────────────────────────────────────────────┘
```

**过滤阶段 (Predicates)：**

```
硬性条件，不满足则排除：

1. 资源是否充足？
   Node 剩余 CPU/内存 >= Pod 请求

2. 端口是否冲突？
   hostPort 是否已被占用

3. 节点选择器？
   nodeSelector: { disktype: ssd }

4. 污点容忍？
   Node 有 taint，Pod 是否 tolerate

5. 亲和性规则？
   nodeAffinity / podAffinity
```

**打分阶段 (Priorities)：**

```
软性偏好，分数越高越好：

1. 资源均衡
   优先选择资源使用更均衡的 Node

2. 镜像已存在
   优先选择已有所需镜像的 Node

3. Pod 亲和性
   相关 Pod 尽量调度到一起

4. Pod 反亲和性
   同类 Pod 分散到不同 Node
```

### 2.4 Controller Manager - 集群的"自动驾驶系统"

```
本质：一组控制器的集合，每个控制器负责一类资源

┌─────────────────────────────────────────────────────────────┐
│                    Controller Manager                        │
│                                                              │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │
│  │ Deployment   │ │ ReplicaSet   │ │ StatefulSet          │ │
│  │ Controller   │ │ Controller   │ │ Controller           │ │
│  └──────────────┘ └──────────────┘ └──────────────────────┘ │
│                                                              │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │
│  │ DaemonSet    │ │ Job          │ │ Node                 │ │
│  │ Controller   │ │ Controller   │ │ Controller           │ │
│  └──────────────┘ └──────────────┘ └──────────────────────┘ │
│                                                              │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────────────┐ │
│  │ Endpoint     │ │ Namespace    │ │ ServiceAccount       │ │
│  │ Controller   │ │ Controller   │ │ Controller           │ │
│  └──────────────┘ └──────────────┘ └──────────────────────┘ │
│                                                              │
│                        ... 更多 ...                          │
└─────────────────────────────────────────────────────────────┘
```

**控制器模式详解：**

```
每个 Controller 都是独立的控制循环：

┌───────────────────────────────────────────────────────────┐
│                  Controller 工作原理                       │
│                                                           │
│   ┌──────────┐     ┌──────────┐     ┌──────────┐         │
│   │ Informer │ ──▶ │WorkQueue │ ──▶ │ Worker   │         │
│   │ (监听)   │     │ (队列)    │     │ (处理)   │         │
│   └──────────┘     └──────────┘     └──────────┘         │
│        │                                  │               │
│        │ Watch API Server                 │ Reconcile    │
│        ▼                                  ▼               │
│   接收资源变更事件              对比期望与现实，执行调和    │
└───────────────────────────────────────────────────────────┘
```

**Deployment Controller 示例：**

```
用户创建 Deployment (replicas: 3)
         │
         ▼
Deployment Controller 监听到事件
         │
         ▼
创建 ReplicaSet (replicas: 3)
         │
         ▼
ReplicaSet Controller 监听到事件
         │
         ▼
创建 3 个 Pod
         │
         ▼
Scheduler 监听到未调度 Pod
         │
         ▼
为每个 Pod 分配 Node
         │
         ▼
Kubelet 监听到本节点的 Pod
         │
         ▼
启动容器
```

---

## 3. Worker Node 组件详解

### 3.1 Kubelet - 节点的"管家"

```
本质：运行在每个 Node 上的代理，负责 Pod 生命周期管理

┌─────────────────────────────────────────────────────────┐
│                       Kubelet                            │
│                                                          │
│   1. 监听 API Server                                     │
│      ─────────────────                                   │
│      获取分配给本节点的 Pod                               │
│                                                          │
│   2. Pod 生命周期管理                                     │
│      ─────────────────                                   │
│      创建、启动、停止、删除容器                            │
│                                                          │
│   3. 健康检查                                             │
│      ─────────────────                                   │
│      执行 liveness/readiness/startup 探针                │
│                                                          │
│   4. 资源监控                                             │
│      ─────────────────                                   │
│      上报节点和 Pod 的资源使用情况                         │
│                                                          │
│   5. 卷管理                                               │
│      ─────────────────                                   │
│      挂载/卸载 Pod 所需的存储卷                            │
└─────────────────────────────────────────────────────────┘
```

**Kubelet 与 CRI：**

```
┌─────────┐      CRI (Container Runtime Interface)
│ Kubelet │ ─────────────────────────────────────────┐
└─────────┘                                          │
                                                     ▼
                              ┌─────────────────────────────┐
                              │    containerd / CRI-O       │
                              └──────────────┬──────────────┘
                                             │
                                             ▼
                              ┌─────────────────────────────┐
                              │         OCI Runtime         │
                              │         (runc)              │
                              └─────────────────────────────┘
                                             │
                                             ▼
                              ┌─────────────────────────────┐
                              │        Linux Kernel         │
                              │   (namespaces, cgroups)     │
                              └─────────────────────────────┘
```

### 3.2 Kube-proxy - 节点的"网络管家"

```
本质：实现 Service 的网络代理和负载均衡

Service IP (虚拟IP) ──▶ Pod IP (真实IP)
```

**三种代理模式：**

```
1. iptables 模式（默认）
   ────────────────────
   - 使用 iptables 规则转发流量
   - 无额外进程开销
   - 大规模 Service 时规则多，性能下降

2. IPVS 模式（推荐大规模）
   ────────────────────
   - 使用内核 IPVS 模块
   - 更高效的负载均衡算法
   - 更好的扩展性

3. userspace 模式（已废弃）
   ────────────────────
   - 流量经过用户空间
   - 性能较差
```

**Kube-proxy 工作原理：**

```
┌────────────────────────────────────────────────────────┐
│                                                        │
│   Client ──▶ ClusterIP:Port ──▶ iptables/IPVS ──▶ Pod │
│              (10.96.0.1:80)      (DNAT)     (10.1.1.5) │
│                                                        │
│   Service 定义:                                        │
│   ┌──────────────────────────────────────────────────┐ │
│   │ apiVersion: v1                                   │ │
│   │ kind: Service                                    │ │
│   │ metadata:                                        │ │
│   │   name: my-service                               │ │
│   │ spec:                                            │ │
│   │   selector:                                      │ │
│   │     app: nginx         # 选择后端 Pod            │ │
│   │   ports:                                         │ │
│   │     - port: 80         # Service 端口           │ │
│   │       targetPort: 8080 # Pod 端口               │ │
│   └──────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────┘
```

---

## 4. 组件交互全景图

### 4.1 一个 Pod 创建的完整流程

```
用户: kubectl apply -f pod.yaml

Step 1: kubectl → API Server
─────────────────────────────
  - kubectl 解析 YAML
  - 发送 POST 请求到 API Server
  - API Server 认证、授权、准入控制

Step 2: API Server → etcd
─────────────────────────────
  - Pod 对象写入 etcd
  - 状态: Pending
  - nodeName: 空

Step 3: Scheduler 监听到未调度 Pod
─────────────────────────────
  - 过滤可用 Node
  - 打分选择最佳 Node
  - 更新 Pod.nodeName = "node-1"

Step 4: API Server → etcd
─────────────────────────────
  - 更新 Pod 对象
  - nodeName: node-1

Step 5: Kubelet (node-1) 监听到 Pod
─────────────────────────────
  - 发现有分配给自己的新 Pod
  - 调用 CRI 创建容器
  - 调用 CNI 配置网络
  - 调用 CSI 挂载存储

Step 6: Kubelet 上报状态
─────────────────────────────
  - Pod 状态: Running
  - 容器状态: Ready
  - 写回 API Server → etcd

                    完成！
```

### 4.2 组件通信模式

```
┌─────────────────────────────────────────────────────────────┐
│                      通信模式                                │
│                                                             │
│   1. 所有组件只与 API Server 通信                            │
│      ────────────────────────                               │
│      - 星型拓扑，API Server 是中心                           │
│      - 组件间不直接通信                                      │
│                                                             │
│   2. Watch 机制                                              │
│      ────────────────────────                               │
│      - 组件 Watch API Server 获取变更                        │
│      - 长连接，事件驱动                                      │
│      - 避免轮询，减少 API Server 压力                        │
│                                                             │
│   3. 乐观并发控制                                            │
│      ────────────────────────                               │
│      - 每个对象有 resourceVersion                            │
│      - 更新时检查版本，冲突则重试                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 5. 总结：架构设计的智慧

```
设计原则                         体现
─────────────────────────────────────────────────────
单一真相来源                     etcd 存储所有状态
声明式 API                       RESTful + 资源导向
控制器模式                       Watch + Reconcile
松耦合                           组件只与 API Server 通信
可扩展性                         CRI/CNI/CSI 插件化
高可用                           Control Plane 可多副本部署
```

> **核心洞见：K8s 架构的本质是一个事件驱动的分布式状态机，etcd 存储状态，API Server 统一入口，Controller 驱动状态变迁。**
